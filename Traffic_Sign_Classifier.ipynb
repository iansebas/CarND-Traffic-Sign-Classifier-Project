{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = \"train.p\"\n",
    "validation_file= \"valid.p\"\n",
    "testing_file = \"test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. **THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES** \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "n_validation = X_valid.shape[0]\n",
    "\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "image_shape = X_train.shape[1:]\n",
    "\n",
    "n_classes = np.unique(y_train).shape[0]\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include an exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOQiYmWXMQcDMLGMOAmZmGfv/iaHOmIsgx7cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efdaba48208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFxxJREFUeJzt3XuwZWV95vHvE8BLBAWkQeRiY0QHdAKaFjHGDCOOctGA\npXgHdIxtMljRKhOnpSojmsHBKW+lMU5hJEC84i1imkQJiopRtEFEEYmgrTQN3c1NIUbk8ps/1ntk\nczh9zu5z6dP99vdTtevs9a7bb79rn2ev8+6910lVIUnq128tdgGSpIVl0EtS5wx6SeqcQS9JnTPo\nJalzBr0kdc6g3wokWZqkkmzfpv8pyYnjLDuLfZ2c5G/nUu/WLMnTk1w1j9v7zbFK8ookF83jtl+W\n5Ivztb2R7R6WZM18b3ex97UtM+g3gyRfSPLWKdqPSXLDpoZyVR1ZVWfNQ133+yWrqrdV1R/PddtT\n7OsVSe5Ocnu7/STJ3yV57CZs48wk/3sONZyS5M4kt7XbvyX56yR7TixTVV+rqseNua0Pz7TcPB6r\n+72AV9VHqupZc932QktySJLzktya5OYk30ryysWua1ti0G8eZwLHJ8mk9uOBj1TVXZu/pEXxjara\nEXgY8EzgP4BLkjxhM9bwiaraCdgVeB7wiFbDntOvtmky2OZ/v5I8FfgS8BXgMcDDgT8FjlzMurY5\nVeVtgW/Ag4GfA3840rYL8CvgoDZ9NPAd4BfAtcApI8suBQrYvk1fCPxxu78d8A7gRuDHwEmTln0l\ncCVwW5v/mtb+EIagvQe4vd0eCZwCfHhk338EXAHc2vZ7wMi81cCfA5e3x/cJ4EEb6YNXABdN0f6P\nwKdGpj8J3NC291Xg8a19OXAn8OtW6+db+wrgmvb4fgA8b5rjcJ/HNtJ/3wXe0aYPA9aMzP+fwHVt\n+1cBhwNHtDrubLV8d+S4nAp8vfXtYyYdq1e0ee9rj++HwOGT+vOZU9UL/Kwd14lj9dTJfQr8PvDt\ntu1vA78/Mu9C4K/a/m8DvgjstpF+OgxYA5zM8LxaDbyszXsysI72/Gptzwcu28i2LgLeP80xmdzf\nGz2erT+/0h7fjQwv2gAB3g2sb/MuB56w2L/3W9Jtmz/j2Byq6j+Ac4ATRppfCPywqr7bpv+9zd+Z\nIfT/NMmxY2z+1cBzgCcCy4AXTJq/vs1/KEPovzvJk6rq3xnOqtZW1Y7ttnZ0xTas8jHg9cAS4Dzg\n80keMOlxHAHsB/wuQ/hsis8ATx+Z/idgf2B34FLgIwBVdXq7/39brc9ty1/T1n8Y8Bbgw5tydl5V\ndwOfm1QDAEkeB7wWeHINfwU8G1hdVf8MvI0haHasqoNGVjue4UVpJ+CnU+zyKQwvuLsBbwY+k2TX\nMUr9w/Zz57bPb0yqdVdgJfBehrPmdwErkzx8ZLGXMjwHdgcewPAivTGPaDXuBZwInJ7kcVX1beAm\n4L+NLPty4O8nbyDJbzO8IH1qjMc3Ybrj+VcML1C7AHszvGACPIuhfx7L8PvzolajGoN+8zkLOC7J\ng9v0Ca0NgKq6sKq+V1X3VNXlDAH7X8bY7guB91TVtVV1M/B/RmdW1cqquqYGX2H4RblfqG3Ei4CV\nVXV+Vd3J8JfDgxnOHCe8t6rWtn1/Hjh4zG1PWMswjDJR7xlVdVtV3cFwRntQkodtbOWq+mTb/z1V\n9QngR8Ahc6lhxN3AA4EDk+xQVaur6poZtnVmVV1RVXe1PptsPcPxurPVexXDC/tcHQ38qKr+vu37\nYwx/MTx3ZJm/q6p/GznxmOlY/WVV3dGeNysZnmswPG9fDr95gXk28NEp1t+FIWOuH/dBzHA87wQe\nBTyyqn5VVReNtO8E/CcgVXVlVY29z22BQb+ZtCflBuCYJI9m+BP4N78cSZ6S5MtJNiT5OfAnDGdU\nM3kkw1DPhPucRSY5Msk325tgtwJHjbndiW3/ZntVdU/b114jy9wwcv+XwI5jbnvCXsDNrdbtkpyW\n5Jokv2AYMmC6epOckOSy9kbfrcATplt+phpGVdXVDH/NnAKsT/LxJI+cYVvXzjD/uqoavZLgTxn6\nea7uc6xGtj3bY3VL+6tvdFsTdX4YeG6SHRnC/2sbCdZbGIYGx/4La4bj+UaGYZpvJbkiyX8HqKov\nAX8NvB9Yl+T0JA8dd5/bAoN+8zqb4Uz+eOCLVbVuZN5HgXOBfarqYcD/Y3hSz+R6YJ+R6X0n7iR5\nIPBphjPxPapqZ4bhl4ntznTp0rUMZ1AT20vb13Vj1DWu5wFfa/dfChzD8Ebtwxjem4CN1JvkUcAH\nGYZXHt4e3/cZr98mtvFbDGe9X5tqflV9tKr+gKEfCnj7VLWMrjLDLvea9Kb8vgz9DMPw3W+PzHvE\nJmz3PsdqZNuzPVa7JHnIpG2tBaiq64BvMBy745li2KYt98u23PPH2eFMx7OqbqiqV1fVI4HXAH+T\n5DFt3nur6veAxzMM4fzFpj3cvhn0m9fZDCH2akaGbZqdgJur6ldJDmEIvXGcA/xZkr2T7MLwZtaE\nBzAMPWwA7kpyJMN45oR1wMOnGRo5Bzg6yeFJdgDeANwB/OuYtU2pnbnvl+R9DG/GvaXN2qlt/yaG\nwHvbpFXXAY8emX4IQwBuaNt9JcMZ4Dg17JDkAIYhskcwjGlPXuZxSZ7RXjB/xfAG690jtSydxSdr\ndmc4XjskOQ44gOHFF+Ay4MVt3uT3WzYwnB0/mqmdBzw2yUuTbJ/kRcCBDG92z9ZbkjwgydMZ3uf5\n5Mi8sxnOsP8z8NlptvFG4BVJ/mLi/YIkByX5+BTLTns8kxyXZO82eUtb9u4kT25/Ee/A8GL5K+49\nTsKg36yqajVDSD6E4ex91P8A3prkNuB/MYTsOD4IfIHhkyOXMry5ObG/24A/a9u6heHF49yR+T9k\nCLoftz+V7zOEUFVXMYzFvo/hUw7PBZ5bVb8es7bJnprkdoZPFl3I8Abxk6vqe23+2QxDBNcxfOLi\nm5PW/xDDePmtSf6hqn4AvJPhrHEdQ+h8fYYaXtRquJWhL24Cfm/yG9HNA4HTGB77DQwhfXKbNxF6\nNyW5dKYHPuJihjebb2T4hM4LqmrijcO/BH6H4Vi9hZGhvXZ2fCrw9fb4Dx3daNvGcxhejG9iCNjn\nVNWNm1DbqBtaHWsZ3gT/k/Z8mfBZhr8gPjtpiOc+qupfgWe024+T3Ayczr0vbqPLznQ8nwxc3I7f\nucDrquonDM+jD7Z6f8rw+N8xi8fcrdx3uFCSxpPkGoaP6/7LYtei6XlGL2mTJXk+w9DJlxa7Fs1s\nVtdDkbTtSnIhw/j/8e2TWNrCOXQjSZ2bcegmyT7t891Xts+uvq61n5LkuvaZ18uSHDWyzpuSXJ3k\nqiTPXsgHIEma3oxn9O3rx3tW1aVJdgIuAY5l+KLE7VX1jknLH8jwSY5DGL5g8S/AY9tXzae02267\n1dKlS+fyOCRpm3PJJZfcWFVLZlpuxjH69o2369v925JcyX2/bTfZMcDH21fYf5LkaobQ/8bGVli6\ndCmrVq2aqRRJ0ogkU11P6X426VM3SZYyXDzr4tb02iSXJzmjfVkHhheB0a+Br2GKF4Yky5OsSrJq\nw4YNm1KGJGkTjB307boWnwZeX1W/AD7A8OWOgxnO+N85segUq99vfKiqTq+qZVW1bMmSGf/ykCTN\n0lhB375a/GmGf5LxGYCqWldVd7ePV32Qe68wt4b7Xntlb+69lockaTMb51M3Yfjq+ZVV9a6R9tEr\n0j2P4eJDMHw1+cVJHphkP4ave39r/kqWJG2Kcb4w9TSGK9R9L8llre1k4CVJDmYYllnNcDU5quqK\nJOcwXKvkLuCk6T5xI0laWON86uYiph53v99FiUbWOZXhAkySpEXmtW4kqXMGvSR1zqCXpM51f/XK\npStWzmq91afNx/9r7tt0fWv/SVsOz+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9J\nnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5\ng16SOmfQS1LnDHpJ6pxBL0mdM+glqXPbL3YBW6OlK1bOet3Vpx09j5WMZ7p6p6tnLo9T2hrN9ndl\nS+cZvSR1zqCXpM4Z9JLUOYNekjo3Y9An2SfJl5NcmeSKJK9r7bsmOT/Jj9rPXVp7krw3ydVJLk/y\npIV+EJKkjRvnjP4u4A1VdQBwKHBSkgOBFcAFVbU/cEGbBjgS2L/dlgMfmPeqJUljmzHoq+r6qrq0\n3b8NuBLYCzgGOKstdhZwbLt/DHB2Db4J7Jxkz3mvXJI0lk0ao0+yFHgicDGwR1VdD8OLAbB7W2wv\n4NqR1da0tsnbWp5kVZJVGzZs2PTKJUljGTvok+wIfBp4fVX9YrpFp2ir+zVUnV5Vy6pq2ZIlS8Yt\nQ5K0icYK+iQ7MIT8R6rqM6153cSQTPu5vrWvAfYZWX1vYO38lCtJ2lTjfOomwIeAK6vqXSOzzgVO\nbPdPBD430n5C+/TNocDPJ4Z4JEmb3zjXunkacDzwvSSXtbaTgdOAc5K8CvgZcFybdx5wFHA18Evg\nlfNasSRpk8wY9FV1EVOPuwMcPsXyBZw0x7okSfPEb8ZKUucMeknqnEEvSZ0z6CWpcwa9JHXOoJek\nzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6Seqc\nQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0\nktQ5g16SOmfQS1LnDHpJ6tyMQZ/kjCTrk3x/pO2UJNcluazdjhqZ96YkVye5KsmzF6pwSdJ4xjmj\nPxM4Yor2d1fVwe12HkCSA4EXA49v6/xNku3mq1hJ0qabMeir6qvAzWNu7xjg41V1R1X9BLgaOGQO\n9UmS5mj7Oaz72iQnAKuAN1TVLcBewDdHllnT2u4nyXJgOcC+++47hzIWxtIVK92nFs10x2X1aUdv\nxkrUg9m+GfsB4HeAg4HrgXe29kyxbE21gao6vaqWVdWyJUuWzLIMSdJMZhX0VbWuqu6uqnuAD3Lv\n8MwaYJ+RRfcG1s6tREnSXMwq6JPsOTL5PGDiEznnAi9O8sAk+wH7A9+aW4mSpLmYcYw+yceAw4Dd\nkqwB3gwcluRghmGZ1cBrAKrqiiTnAD8A7gJOqqq7F6Z0SdI4Zgz6qnrJFM0fmmb5U4FT51KUJGn+\n+M1YSeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXO\noJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1bsZ/Di5tSZauWDmr9VafdvQ8V6LF\nNN3zwGN9f57RS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9J\nnTPoJalzBr0kdW7GoE9yRpL1Sb4/0rZrkvOT/Kj93KW1J8l7k1yd5PIkT1rI4iVJMxvnjP5M4IhJ\nbSuAC6pqf+CCNg1wJLB/uy0HPjA/ZUqSZmvGoK+qrwI3T2o+Bjir3T8LOHak/ewafBPYOcme81Ws\nJGnTzXaMfo+quh6g/dy9te8FXDuy3JrWJklaJPP9ZmymaKspF0yWJ1mVZNWGDRvmuQxJ0oTZBv26\niSGZ9nN9a18D7DOy3N7A2qk2UFWnV9Wyqlq2ZMmSWZYhSZrJbIP+XODEdv9E4HMj7Se0T98cCvx8\nYohHkrQ4Zvzn4Ek+BhwG7JZkDfBm4DTgnCSvAn4GHNcWPw84Crga+CXwygWoWZK0CWYM+qp6yUZm\nHT7FsgWcNNeiJEnzx2/GSlLnDHpJ6pxBL0mdm3GMXpqNpStWzmq91acdPc+VaKFNd6xnOp5zWVfj\n84xekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z\n6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNe\nkjq3/WIXsK1ZumLlYpewRVuM/lmMfa4+7ehZrztdvdNtd6bHOZd1F8Js9zmXxzlbc+mfhahnMs/o\nJalzBr0kdc6gl6TOGfSS1Lk5vRmbZDVwG3A3cFdVLUuyK/AJYCmwGnhhVd0ytzIlSbM1H2f0/7Wq\nDq6qZW16BXBBVe0PXNCmJUmLZCGGbo4Bzmr3zwKOXYB9SJLGNNegL+CLSS5Jsry17VFV1wO0n7vP\ncR+SpDmY6xemnlZVa5PsDpyf5IfjrtheGJYD7LvvvnMsQ5K0MXM6o6+qte3neuCzwCHAuiR7ArSf\n6zey7ulVtayqli1ZsmQuZUiSpjHroE/ykCQ7TdwHngV8HzgXOLEtdiLwubkWKUmavbkM3ewBfDbJ\nxHY+WlX/nOTbwDlJXgX8DDhu7mVKkmZr1kFfVT8GDpqi/Sbg8LkUJUmaP34zVpI6Z9BLUucMeknq\nnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdS1Utdg0sW7asVq1aNat1\nl65YOc/VSNLms/q0o2e9bpJLRv5f90Z5Ri9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucM\neknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCX\npM4Z9JLUOYNekjq3YEGf5IgkVyW5OsmKhdqPJGl6CxL0SbYD3g8cCRwIvCTJgQuxL0nS9BbqjP4Q\n4Oqq+nFV/Rr4OHDMAu1LkjSN7Rdou3sB145MrwGeMrpAkuXA8jZ5e5KrZrmv3YAbZ7nutsI+mp79\nMzP7aHqz7p+8fU77fdQ4Cy1U0GeKtrrPRNXpwOlz3lGyqqqWzXU7PbOPpmf/zMw+mt6W3j8LNXSz\nBthnZHpvYO0C7UuSNI2FCvpvA/sn2S/JA4AXA+cu0L4kSdNYkKGbqroryWuBLwDbAWdU1RULsS/m\nYfhnG2AfTc/+mZl9NL0tun9SVTMvJUnaavnNWEnqnEEvSZ3bqoPeyyzcX5IzkqxP8v2Rtl2TnJ/k\nR+3nLotZ42JKsk+SLye5MskVSV7X2u0jIMmDknwryXdb/7ylte+X5OLWP59oH7LYZiXZLsl3kvxj\nm96i+2erDXovs7BRZwJHTGpbAVxQVfsDF7TpbdVdwBuq6gDgUOCk9ryxjwZ3AM+oqoOAg4EjkhwK\nvB14d+ufW4BXLWKNW4LXAVeOTG/R/bPVBj1eZmFKVfVV4OZJzccAZ7X7ZwHHbtaitiBVdX1VXdru\n38bwy7oX9hEANbi9Te7QbgU8A/hUa99m+wcgyd7A0cDftumwhffP1hz0U11mYa9FqmVLt0dVXQ9D\n0AG7L3I9W4QkS4EnAhdjH/1GG5a4DFgPnA9cA9xaVXe1Rbb137X3AG8E7mnTD2cL75+tOehnvMyC\ntDFJdgQ+Dby+qn6x2PVsSarq7qo6mOEb7YcAB0y12OatasuQ5DnA+qq6ZLR5ikW3qP5ZqGvdbA5e\nZmF865LsWVXXJ9mT4Uxtm5VkB4aQ/0hVfaY120eTVNWtSS5keC9j5yTbt7PWbfl37WnAHyU5CngQ\n8FCGM/wtun+25jN6L7MwvnOBE9v9E4HPLWIti6qNp34IuLKq3jUyyz4CkixJsnO7/2DgmQzvY3wZ\neEFbbJvtn6p6U1XtXVVLGTLnS1X1Mrbw/tmqvxnbXlXfw72XWTh1kUtadEk+BhzGcNnUdcCbgX8A\nzgH2BX4GHFdVk9+w3SYk+QPga8D3uHeM9WSGcfptvo+S/C7Dm4nbMZwInlNVb03yaIYPPOwKfAd4\neVXdsXiVLr4khwF/XlXP2dL7Z6sOeknSzLbmoRtJ0hgMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0\nktS5/w8zhKkdCmLyHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efda7f0b860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efda7e0ab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAD9RJREFUeJztnEuMXclZx39fnfvqx+3X2G174vG8NIhlkBAs2CAhJMQm\nsACRBQIJKWwiBciCiBXLLJhskQYRiQUSQgKJLCKhCMGCDcoQRYRhMg+P7Rk/prvtft3neVQVi++r\nc9ue8fS12zljje8n2ff2OXWq6n7nX9+7SmKMLKgZcp/3BJ4lWjC7QVowu0FaMLtBWjC7QVowu0Fa\nMLtBOhOzReQ3ROQdEXlfRL71pCb1RSV5XKdGRDLgXeDXgZvAD4Gvxhj/78lN74tFrTM8+0vA+zHG\nDwBE5B+ArwAPZfba2lrc3t4GQNLFT34hcj8A5MT/80EjnugtPXfySUnNeODLJ27N+jl5cXZXgJ3d\nXY6Pju9r+ml0FmZ/CfjoxN83gV9+sJGIfA34GsD58+f5zuuvE4Mncza3zCSZ06nEGAnB27Opj4gu\nJAj2OxM7AycYYqvURU8m2m+wTnwI2hcgaF8+rWq7l7lIJfrd23MZMuNt1HsuXRCHw/Fnf/rNh3Pp\nBJ2F2Z/2Jj8BvBjjG8AbAK+99loU58AJwSZeP+GruouZItGbMYQZ5xNSTzAv3Ts5IZ/46LVdMMaK\nAMbQJELTczFGSC+67sfVf2XO5oO2cUAVIvNK4rMw+ybwwom/LwO3P+uBGCPee3BSIy3GNHFFmxOp\n+RrthYgEoty/sBOz9f79IiYiRNLLSFcNsYGZGEgATYjNMlzM7uvfZbMeYrBVYnOtbFnNq/XOYo38\nEHhNRF4WkQ7we8D3ztDfF54eG9kxxkpEvg78K5AB340xvnXqcyEguBq9CaCBtMxnUEnIjjHi6xWQ\nln6C5QkJE02Oh0BVFQBUSVw5xZUTqRGWVksMVepqBtOkHGQmwryJpPRZlZ5Wu828Ft1ZxAgxxu8D\n3z9LH88SnYnZj0oxRkKMSJwplaQOQ0xQj7W2F2sUhRpdVakoTMaMEyhK/V7alyLPmYwGAAwmQ2uo\nP3VzfYOl3hInOxEbL0hFO1N53LKVUFaxtlqqSvuvvK4aX0WgV6/A02jhrjdIzSIbKKNHwsw69maj\nOUOSj7G2FuSEnq8tAlsBZZUDMBmPOTg4AmBwfAzA+PCIfKjXRoZwzO5e39hidW0NgM5yD4ClZUV6\nv9+n31/XcQzhU+8ZjUc6ZjEBoJUlpAdCb5Xo50N2o8xWP86jjH5gUSVlSCBN3ZnoCN5MRiDPdQkP\nD+4B8PFHN9i5fQuAw3t3ASiGQygKe9bsd2P2TpbR7nYAWO6vALBxbhOA7UsvUly4AkBvdVn78hVH\ng0MARscHAHQ6SaR5VlZLqtpH+GxaiJEGqWFkWzTBFGW6cvLDISSh4U1kRA9DExG7u7sA3Lz6LgBH\nH15ncqiIK8dj7cR7MntWXFLApmxjpDCIBXtucncPgNHBkMNDVaj98+cB6C6vkJcqPpKYCkEVZavV\nxgdXr7rTaIHsBqlRZAuCSKbBoGROJVkdUuBo5k8kc3A8mPDxbY0EXHv7JwDsXHtPnxsNiWWo+wfI\nOh2kp/I4a6l8Tho2n06pDKlFobI2lroiJvkNjgaqWFcPngdg+/IVpK39jsb6nC8V2RtrGcGXzBsc\nad4a8ZFWjPUEQ4qRuNmEK7s3LVXJ3b23y/s/Ved0/72fAuDGqrScZHTWtgBYfU6X/tqli/iuWhqu\n1cYGAsBPc8bH+ux4oGJhsLtjfY44tu9lYqCLuF4XgOFQRUzbRNNSltFdXp379y/ESIPUuAepHqBD\nUlRuFt8EoAq+Nv2SF3jznbfYe+9tAMJYl/lSR+3gje3nWbvwKgBr25f0wW5GYX04M/lq2z3C6nPn\nACgmaj8fmJ29+8FVKlOyk3uqNFvO01lT07CsVOxU1uURwNIaPswnRhbIbpAaN/1wQvCVRYSpnY0U\nOYsIwSvcb934EICdq+/SHluMo6Xyc/PiywD0L16hs6GyemyyVEJFZh5gtKVTWp+j6ZRian1ZZLCz\nqam6zRcj/tr7Os1cleFw9x5rFuN2PdUDeaWm3qQ1JRseEham39NHzSNbLLQc7s+qpYRsiMLoSGXp\n/oeK7OL4AGcucXfjOQBaW5cBGHe3uH5LHZ1gJtzmWosL51QuZ12Vx0f7iubr164xHKlbn6ye/pLG\nQ37+ymVayQK6/oG2KUsmZoUk8V+ZiZlPJiwvTeaO+jVu+vkqqJcY7p+gt7xe4YXBoSrB6V318Pwk\np9NW8dHbUmXl+srE63dvc+fOxwCsZNrnwd6EyUjNuouXvwTAtesqHqbDKdvnNP4xsYTE4d4dAAaT\nCdvb+hKHe6ogq8E+MSUiUrwlU7Z1W6vgT02q17QQIw1Ssx5khCxEgkjtJWLKJTpFZVkFBhazyI8U\nnURoWVh06eJFAI6rKQDTnZu8uqUiY2tbP6/v3eLGVBWcmDLMUa9vZWOVF154Sa8VGqYtjzWCWOYF\nbsPEz5qKFoaHREtYYIqxlalX2snaFLknLky/p4+aVZACmROttahFnZl+piCLqmQ6UWdGSkVvFKG1\norGOTr+v7Q4UsS5G1s1lXu6uWvslfMv6i6noJhUDCcurasrJRK9lhtQiL8h6ypKlDdUNx3fuICnR\nW1nspafP55Mcn1UnIpifTY1bIx4LNj2w9FLQyVeBqlAmYzk/nKO9rMzumaJcXdYffG+5z9U7NwFY\ntyDSYH+f1S21ifsWI9l1Znd7TxDtV1ZVyUazWMoyx5qRWZ4y4uoakpRVqmzuefBUIcydXV+IkQap\n4diIBvFDiHW0r65mSomCCHXZWZ0qkxr5IjplJ4rwENpMp2q6dVA7u00gK2zJT1W59c1cIy/AW/Df\naUSwnelnNR3BAzGbGCPRStKCmYqlZddDGYnSWiD7aaTGE74+eCRKnTxI1azxREWUsxoPrHI1xqLO\nvldmKlYWwG9VOS9e0ED/xvoGAEVo8e41jX8Pbt8AwB2qV+raPbLcxirV9OsacosY6sSzn6rekOCR\nVIhpkcMymavicM59osT5YXQqskXkBRH5dxF5W0TeEpFv2PUtEfmBiLxnn5tzjfgM0zzIroBvxhh/\nJCJ94L9F5AfAHwL/FmP8tm3x+Bbw56d1lokQQqirnpwh2zxtOq5Fr6fmXTDLI0yGjPfV8Vg1N3xW\n3ldSoe03tzSuvXMwINiqoKMo7J9X1O8d5Xy0p2bj5ro6Lt5qUAIRX+q8xkM1P0OoyDKbYyuZqZbC\n85EQiieXFosx3gHu2PeBiLyNFsJ/BfhVa/Z3wH9wGrNjJHoPxFqp+KR8jNktJ6ysqL3c6+vnaHCX\naEU3+fG+NlzSgFTodBhVqhhv7WjwaJyXuI4qPb+kHqFbUmYfTz7maEdr+Lu3rmkbSxi88tLLhGCF\n8lbKFgUye+nOqT2eSjMzoKj83PXZj6QgReQl4BeA/wIu2ItIL2T7Ic98TUTeFJE3BxY9e1ZpbgUp\nIqvAPwF/EmM8Fpkv2nVy58FLL78cRYQQ4kwhGqTrxK+AdBWVXVvm2W4bb8H8fF/DoxsvaArsubUN\n9u6qEry6r5/tbpv19QsAbJ97Rcdpq1NUFC3GI62gihMdc/O8RgFfufwid95TtA8skigOYnfZ5mYm\nolexI61s7kJ4mBPZItJGGf33McZ/tss7InLJ7l8Cdh9h3GeSTkW2KIT/Fng7xvidE7e+B/wB8G37\n/JfT+ooxUlYl4txsP9cDxeeVD9BWudnb1BKF9tIafqCy+mhH32l/TdH50sVtzm39HACjicreXq/D\n+rrK9N6KKk8rLaF/5SIEi4lbvKRTqSzeu/oOBx/pZrfloKaiX+6SrZqizlWOeyueD6W66k+yGP5X\ngN8HfiIiP7Zrf4Ey+R9F5I+AD4HfmWvEZ5jmsUb+k0/fGQbwa480Wox4b8Xu9ZY5cxAssua8p2Pb\n9fobiuzN56+wd01RW1n57p0PtLThEhVbFzS7smWROlrteltHygAlE7PlhMwn113v3ftI028HN29Q\nlWr1tLravrPRZ2IufG5RyDrUQHik3ZkNp8U0c64FkxpfEMst1jv1vCdzyoTusu0WuPAc1VQV4oFF\n+KYD/eG3r37AxEy3pU0187qrW3SWVamJ0/69mXRFnhMmqRJKYyr3bmppW5wcJ6eVdl8z9iPf43Cq\nL7iq67BTvjSQubpO4FRaxEYapGZjI7YPMvOBaGW3pcUnSosVx8yR27W0ubPdbbG1rUgLFrE73FOP\nMh+M2Z9qMrdnyrO3ssWqmY2pZLgq9XM6mpBPVNlOBwd2L5lyjs66iqKxOTDHk6KuhJptn0zItqjg\nnD9/gewGqVFkhxDIp0MyfF12Ox6r7PU2FddtM7Hqp8nAPM6yorWkMnjlnDorVdD2xcEerlIZXBwf\n2eeU449VHksdG7d4RohouAcyU3ytrpp2rY0tpia09wcDGyfMonqp8jb1iXAiv3cqNZw8CFRlwbSY\nMjGbeDzRJdzqaPqqTY+x1UGPhtom+liX6dreAgqLfbj+Kj3Ms7O+8klV5w0j9yu12Mpod5btklkq\nK5oCO3QZx0N9+YXViEQCYvb4jK3Wpziim5/ZCzHSIDWf8A2R0SRnMFBzKreYR8fqQDqskOe6zCeW\n0ppOyzoMmrbkTSdWOiwR11JkurYitrsSyR48UMBsy0pmIdIyNxQb6u8eH1IWFvqtxc8JRMb7U2bO\nmc39s4j6Lehs1CiyfQgMRkOOBuN6y4S3soWyMoUXom1TPuGxxUhhJl9Kh1WVomwQA8O01bGlyi1z\nQqej/XUMhvm0sD7L+hCBtEcyebG+KmvvsK6ijLMI5ey0GWxe6tgsTL+nkBpFduYcG6t9hoPxDEGW\nPPVF0up5vc+wKgz9viJW6bgKk6lWFF+WFQlqoUpF6SV5YeXDWxs2tsrzyf4hpSG7jhHY805cfVrO\n7KSfWfVWlhLRabwQzNN5CmMjxAD5mP5ym7LQYP7U0k+uSj8yrz22YKKinOZkcn8MIm3pEye0WunM\nJ7s3LXCifbTSGVRtNS31fBATI2k7YAqCiaMMSSbNtKCk+EeaQ30EkqPTac327ZxCCzHSID32uX6P\nNZjIHjAC7jY26OPTOeaf54sxxvOnNWqU2QAi8maM8RcbHfQx6Gcxz4UYaZAWzG6QPg9mv/E5jPk4\n9MTn2bjMfpZpIUYapMaY/TSftf0Zlbp/KSK3ROTH9u83zzROE2LkaT9r2yq6Lp2s1AV+C/hdYBhj\n/KsnMU5TyK7P2o7qK6eztp8KijHeiTH+yL4PgFSp+0SpKWZ/2lnbT/zHPAl6oFIX4Osi8j8i8t2z\nFvw3xey5ztr+vOnBSl3gr4FXgS+jNeqvn6X/ppj9yGdtN02fVqkbY9yJMfqo29b+BhWHj01NMfup\nPmv7YZW6qSTa6LeB/z3LOI3Esx/3rO0G6WGVul8VkS+jIu868MdnGWThQTZICw+yQVowu0FaMLtB\nWjC7QVowu0FaMLtBWjC7QVowu0H6fxBzzi8cMvdeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efda7d0b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "\n",
    "# Distributions\n",
    "binwidth = 1\n",
    "plt.hist(y_train, bins=np.arange(min(y_train), max(y_train) + binwidth, binwidth))\n",
    "plt.title(\"Training Data Distribution by Class\")\n",
    "plt.show()\n",
    "plt.hist(y_valid, bins=np.arange(min(y_valid), max(y_valid) + binwidth, binwidth))\n",
    "plt.title(\"Validation Data Distribution by Class\")\n",
    "plt.show()\n",
    "plt.hist(y_test, bins=np.arange(min(y_test), max(y_test) + binwidth, binwidth))\n",
    "plt.title(\"Testing Data Distribution by Class\")\n",
    "plt.show()\n",
    "\n",
    "# Example image\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "print(y_train[index])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set (normalization, grayscale, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimally, the image data should be normalized so that the data has mean zero and equal variance. For image data, `(pixel - 128)/ 128` is a quick way to approximately normalize the data and can be used in this project. \n",
    "\n",
    "Other pre-processing steps are optional. You can try different techniques to see if it improves performance. \n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "\n",
    "# Normalize Data\n",
    "X_train = (X_train - 128)/128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # SOLUTION: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, n_classes), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "\n",
    "def dnn(x):\n",
    "    \n",
    "    y = LeNet(x)\n",
    "    \n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 1 and 3 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,32,32,1], [5,5,3,6].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    669\u001b[0m           \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors_as_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           status)\n\u001b[0m\u001b[1;32m    671\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 1 and 3 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,32,32,1], [5,5,3,6].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d3d64ce9ad70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mone_hot_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_hot_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mloss_operation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-44bf4e6141b8>\u001b[0m in \u001b[0;36mdnn\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-44bf4e6141b8>\u001b[0m in \u001b[0;36mLeNet\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mconv1_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mconv1_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mconv1\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'VALID'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconv1_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# SOLUTION: Activation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m    394\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                                 \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m    397\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    757\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    758\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2240\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2242\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2243\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1615\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1617\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1618\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 1 and 3 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,32,32,1], [5,5,3,6]."
     ]
    }
   ],
   "source": [
    "# Helper Definitions\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, n_classes)\n",
    "\n",
    "logits = dnn(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n",
    "# Train & Validate\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #self.saver.restore(sess, model)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, 'model')\n",
    "    print(\"Model saved\")\n",
    "    \n",
    "    \n",
    "# Test    \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model')\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "To give yourself more insight into how your model is working, download at least five pictures of German traffic signs from the web and use your model to predict the traffic sign type.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Run the predictions here and use the model to output the prediction for each image.\n",
    "### Make sure to pre-process the images with the same pre-processing pipeline used earlier.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Calculate the accuracy for these 5 new images. \n",
    "### For example, if the model predicted 1 out of 5 signs correctly, it's 20% accurate on these new images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the new images, print out the model's softmax probabilities to show the **certainty** of the model's predictions (limit the output to the top 5 probabilities for each image). [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#top_k) could prove helpful here. \n",
    "\n",
    "The example below demonstrates how tf.nn.top_k can be used to find the top k predictions for each image.\n",
    "\n",
    "`tf.nn.top_k` will return the values and indices (class ids) of the top k predictions. So if k=3, for each sign, it'll return the 3 largest probabilities (out of a possible 43) and the correspoding class ids.\n",
    "\n",
    "Take this numpy array as an example. The values in the array represent predictions. The array contains softmax probabilities for five candidate images with six possible classes. `tk.nn.top_k` is used to choose the three classes with the highest probability:\n",
    "\n",
    "```\n",
    "# (5, 6) array\n",
    "a = np.array([[ 0.24879643,  0.07032244,  0.12641572,  0.34763842,  0.07893497,\n",
    "         0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.08594638,  0.0178669 ,  0.18063401,\n",
    "         0.15899337],\n",
    "       [ 0.26076848,  0.23664738,  0.08020603,  0.07001922,  0.1134371 ,\n",
    "         0.23892179],\n",
    "       [ 0.11943333,  0.29198961,  0.02605103,  0.26234032,  0.1351348 ,\n",
    "         0.16505091],\n",
    "       [ 0.09561176,  0.34396535,  0.0643941 ,  0.16240774,  0.24206137,\n",
    "         0.09155967]])\n",
    "```\n",
    "\n",
    "Running it through `sess.run(tf.nn.top_k(tf.constant(a), k=3))` produces:\n",
    "\n",
    "```\n",
    "TopKV2(values=array([[ 0.34763842,  0.24879643,  0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.18063401],\n",
    "       [ 0.26076848,  0.23892179,  0.23664738],\n",
    "       [ 0.29198961,  0.26234032,  0.16505091],\n",
    "       [ 0.34396535,  0.24206137,  0.16240774]]), indices=array([[3, 0, 5],\n",
    "       [0, 1, 4],\n",
    "       [0, 5, 1],\n",
    "       [1, 3, 5],\n",
    "       [1, 4, 3]], dtype=int32))\n",
    "```\n",
    "\n",
    "Looking just at the first row we get `[ 0.34763842,  0.24879643,  0.12789202]`, you can confirm these are the 3 largest probabilities in `a`. You'll also notice `[3, 0, 5]` are the corresponding indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Print out the top five softmax probabilities for the predictions on the German traffic sign images found on the web. \n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
